{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae4030c6",
   "metadata": {},
   "source": [
    "# Logistic Regression Classification Task\n",
    "\n",
    "This notebook implements **binary classification using Logistic Regression** as part of the internship task.\n",
    "\n",
    "## Steps:\n",
    "1. Load and explore dataset  \n",
    "2. Train/Test split and standardize features  \n",
    "3. Fit Logistic Regression model  \n",
    "4. Evaluate with confusion matrix, precision, recall, ROC-AUC  \n",
    "5. Tune threshold and explain sigmoid function  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a93c8b",
   "metadata": {},
   "source": [
    "## 1. Load Dataset\n",
    "\n",
    "We use the provided dataset (`data.csv`). Let's first inspect its structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acfa405",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(\"data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787d2590",
   "metadata": {},
   "source": [
    "## 2. Train/Test Split & Standardization\n",
    "\n",
    "We split the dataset into training and testing sets, and standardize features for better model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a547fb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming last column is target\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9f9e75",
   "metadata": {},
   "source": [
    "## 3. Logistic Regression Model\n",
    "\n",
    "We fit a Logistic Regression model using **scikit-learn**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795917ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train model\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = log_reg.predict(X_test)\n",
    "y_prob = log_reg.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa017ffb",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation\n",
    "\n",
    "We evaluate using:\n",
    "- Confusion Matrix  \n",
    "- Precision, Recall, F1-score  \n",
    "- ROC Curve & AUC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54a2d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Confusion Matrix & Classification Report\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# ROC-AUC\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "print(\"ROC-AUC Score:\", auc)\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {auc:.2f}\")\n",
    "plt.plot([0,1],[0,1],'--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3819bd68",
   "metadata": {},
   "source": [
    "## 5. Threshold Tuning & Sigmoid Function\n",
    "\n",
    "By default, Logistic Regression uses **0.5** as the decision threshold.  \n",
    "We can adjust this threshold to balance between **precision** and **recall**.\n",
    "\n",
    "The **sigmoid function** maps any real value into the range (0,1):  \n",
    "\n",
    "\\[ \\sigma(z) = \\frac{1}{1 + e^{-z}} \\]\n",
    "\n",
    "This gives the probability of belonging to the positive class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e29534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example of threshold tuning\n",
    "threshold = 0.3\n",
    "y_pred_thresh = (y_prob >= threshold).astype(int)\n",
    "\n",
    "print(\"Confusion Matrix with threshold=0.3:\\n\", confusion_matrix(y_test, y_pred_thresh))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_thresh))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbeab267",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We successfully built a binary classifier using Logistic Regression, evaluated it using multiple metrics, and explored how threshold tuning affects results.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
